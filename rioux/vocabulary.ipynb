{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .appName('Analyzing the vocabulary of Pride and Prejudice')\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import tempfile\n",
    "\n",
    "url = 'https://www.gutenberg.org/cache/epub/1342/pg1342.txt'\n",
    "response = requests.get(url)\n",
    "text = response.text\n",
    "\n",
    "with tempfile.NamedTemporaryFile(delete=False, mode='w') as temp_file:\n",
    "    temp_file.write(text)\n",
    "    temp_path = temp_file.name\n",
    "\n",
    "book = spark.read.text(temp_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- value: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "book.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('value', 'string')]\n"
     ]
    }
   ],
   "source": [
    "print(book.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+\n",
      "|                                             value|\n",
      "+--------------------------------------------------+\n",
      "|The Project Gutenberg eBook of Pride and Prejudice|\n",
      "|                                                  |\n",
      "|This ebook is for the use of anyone anywhere in...|\n",
      "|most other parts of the world at no cost and wi...|\n",
      "|whatsoever. You may copy it, give it away or re...|\n",
      "|of the Project Gutenberg License included with ...|\n",
      "|at www.gutenberg.org. If you are not located in...|\n",
      "|you will have to check the laws of the country ...|\n",
      "|                          before using this eBook.|\n",
      "|                                                  |\n",
      "|                        Title: Pride and Prejudice|\n",
      "|                                                  |\n",
      "|                               Author: Jane Austen|\n",
      "|                                                  |\n",
      "|          Release date: June 1, 1998 [eBook #1342]|\n",
      "|                Most recently updated: June 17,...|\n",
      "|                                                  |\n",
      "|                                 Language: English|\n",
      "|                                                  |\n",
      "|Credits: Chuck Greif and the Online Distributed...|\n",
      "|                                                  |\n",
      "|                                                  |\n",
      "|*** START OF THE PROJECT GUTENBERG EBOOK PRIDE ...|\n",
      "|                                                  |\n",
      "|                                                  |\n",
      "+--------------------------------------------------+\n",
      "only showing top 25 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 25 rows and truncate the row to 80 characters\n",
    "\n",
    "book.show(25,truncate=50, vertical=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                line|\n",
      "+--------------------+\n",
      "|[The, Project, Gu...|\n",
      "|          [, , , , ]|\n",
      "|[This, ebook, is,...|\n",
      "|[most, other, par...|\n",
      "|[whatsoever., You...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "lines = book.select(split(book.value, ' ').alias('line'))\n",
    "lines.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      The|\n",
      "|  Project|\n",
      "|Gutenberg|\n",
      "|    eBook|\n",
      "|       of|\n",
      "+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import explode, col\n",
    "\n",
    "words = lines.select(explode(col('line')).alias('word'))\n",
    "words.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|word_lower|\n",
      "+----------+\n",
      "|       the|\n",
      "|   project|\n",
      "| gutenberg|\n",
      "|     ebook|\n",
      "|        of|\n",
      "+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lower\n",
    "\n",
    "words_lower = words.select(lower(col('word')).alias('word_lower'))\n",
    "words_lower.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|         |\n",
      "|         |\n",
      "|         |\n",
      "|         |\n",
      "|         |\n",
      "|     this|\n",
      "|    ebook|\n",
      "+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "words_clean = words_lower.select(\n",
    "    regexp_extract(col('word_lower'), '[a-z]+', 0).alias('word') \n",
    ")\n",
    "words_clean.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|     word|\n",
      "+---------+\n",
      "|      the|\n",
      "|  project|\n",
      "|gutenberg|\n",
      "|    ebook|\n",
      "|       of|\n",
      "|    pride|\n",
      "|      and|\n",
      "|prejudice|\n",
      "|     this|\n",
      "|    ebook|\n",
      "|       is|\n",
      "|      for|\n",
      "|      the|\n",
      "|      use|\n",
      "|       of|\n",
      "+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_nonull = words_clean.filter(col('word') != \"\")\n",
    "words_nonull.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- word: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "words_nonull.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4842|\n",
      "|  to| 4399|\n",
      "|  of| 3959|\n",
      "| and| 3785|\n",
      "| her| 2281|\n",
      "|   i| 2105|\n",
      "|   a| 2080|\n",
      "|  in| 2039|\n",
      "| was| 1877|\n",
      "| she| 1744|\n",
      "|that| 1639|\n",
      "|  it| 1597|\n",
      "| not| 1526|\n",
      "| you| 1444|\n",
      "|  he| 1359|\n",
      "| his| 1302|\n",
      "|  be| 1280|\n",
      "|  as| 1240|\n",
      "| had| 1186|\n",
      "|with| 1148|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = words_nonull.groupBy(col('word')).count()\n",
    "results.orderBy(col('count').desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.write.csv('data/vocabulary_count.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "vscode_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
